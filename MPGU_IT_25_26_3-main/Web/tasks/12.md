## Web 12. Основы PostgreSQL (максимальный балл 10, дедлай 02.12.2025 включительно)

## Критерии оценки (максимум 10 баллов)
За выполнение каждого пункта начисляется 1 балл

---

### ⚠️ Штрафы за стиль (до –2 баллов суммарно)

* Смешанный регистр ключевых слов (`create TABLE` вместо `CREATE TABLE`) — −0.5
* Отсутствие отступов или переносов строк — −0.5
* CamelCase в именах таблиц/колонок — −0.5
* Отсутствие `;` в конце операторов — −0.5

---

<details>
<summary><strong style="font-size: 16px;">Вариант 1</strong></summary>

В вашей HR-системе приходят CSV-файлы от рекрутинговых агентств и внутренних отделов: контакты кандидатов, теги-скиллы, поля с зарплатой (иногда с разделителями тысяч), артикулы оборудования/ID, а также строки логов обработки. Перед загрузкой данных в основную базу нужно выполнить проверку и очистку — найти корректные/некорректные значения, нормализовать телефоны, извлечь emails, разбить теги и корректно парсить «грязные» CSV-поля.

Вам дано таблица `hr_import_lines`, куда попадают необработанные строки импорта. Требуется написать SQL-запросы с использованием регулярных выражений и функций PostgreSQL для анализа и предварительной очистки.

---

## SQL — создание и наполнение таблицы (реалистичные примеры)

```sql
DROP TABLE IF EXISTS hr_import_lines;
CREATE TABLE hr_import_lines (
  id serial PRIMARY KEY,
  source_file text NOT NULL,      -- имя файла-источника
  line_no int NOT NULL,           -- номер строки в файле
  raw_line text NOT NULL,         -- исходная необработанная строка
  imported_at timestamp with time zone default now(),
  note text                       -- служебная метка (для ревью)
);

INSERT INTO hr_import_lines (source_file, line_no, raw_line, note) VALUES
-- Контактные строки с email в угловых скобках и без
('candidates_2025_10.csv', 1, 'Ivan Ivanov <ivan.ivanov@example.com>, +7 (912) 345-67-89, \"python,sql\"', 'contact record'),
('candidates_2025_10.csv', 2, 'Мария Смирнова, maria.smirnova@company.co, 8-912-3456789, \"python,django\"', 'contact record'),
('candidates_2025_10.csv', 3, 'Petrov <not-an-email@@example..com>, 09123456789, \"rust, systems\"', 'broken email'),

-- Записи о оборудовании / внутренние ID (артикулы, SKU, asset IDs)
('assets_import.csv', 10, 'ASSET: AB-123-XY; location: HQ; qty: 2', 'asset record'),
('assets_import.csv', 11, 'asset: zx9999; note: legacy-id', 'asset record'),

-- Теги/скиллы в одной колонке, через запятую, с разными пробелами
('skills_teams.csv', 1, 'tags: sql, postgres, regex,  performance', 'tags field'),
('skills_teams.csv', 2, 'tags: fastapi,python', 'tags field'),
('skills_teams.csv', 3, 'tags: sql,, ,postgres', 'possible empty tags'),

-- «Грязные» CSV-поля: кавычки и запятые внутри полей (адреса, зарплаты с разделителем тысяч)
('payroll_dirty.csv', 5, '\"Ivanov, Ivan\", Москва, \"30,000\"', 'csv row with commas'),
('payroll_dirty.csv', 6, '\"Sidorova, Anna\", "St.Petersburg, Nevsky", "1,200,000"', 'csv row with many commas'),

-- Логи обработки и сообщения об ошибках разного регистра
('import_log.txt', 201, 'INFO: Started import of candidates_2025_10.csv', 'log'),
('import_log.txt', 202, 'Warning: missing email for line 3', 'log'),
('import_log.txt', 203, 'error: failed to parse csv_row at line 6', 'log'),
('import_log.txt', 204, 'Error: phone number invalid', 'log'),

-- Ловушки/нестандартные случаи (реалистичные, чтобы выявить наивные решения)
('candidates_2025_10.csv', 20, 'Contact: bad@-domain.com, +7 912 ABC-67-89, \"node, js\"', 'trap-invalid-email-and-phone'),
('assets_import.csv', 12, 'SKU: 12-AB-!!; qty: one', 'trap-bad-sku');
```

---

## Задания (что нужно сделать — формулировка для студента / проверки)

1. Найти все строки, содержащие корректный email (включая случаи с email в угловых скобках) — используйте оператор `~`.
2. Найти строки, **не** содержащие корректный email — используйте оператор `!~`.
3. Найти строки журналов/логов (`source_file = 'import_log.txt'`), где встречается слово `error` в любом регистре — используйте `~*`.
4. Среди логов найти строки, где слово `error` **не** встречается (регистронезависимо) — используйте `!~*`.
5. Извлечь первый найденный email-адрес из поля `raw_line` для каждой строки, где он есть, с помощью `regexp_match` (вернуть id, source_file, line_no и email).
6. Извлечь все product/asset-коды (например `AB-123-XY` и похожие форматы) из `raw_line` с `regexp_matches` (учесть множественные совпадения).
7. Нормализовать телефонные номера: для строк с телефонами вернуть строку с только цифрами (удалить пробелы, скобки, плюс и дефисы) с помощью `regexp_replace`.
8. Для строк с `tags:` разбить список тегов на массив тегов (убрать лишние пробелы) с помощью `regexp_split_to_array`.
9. Для строк с пометкой CSV (`payroll_dirty.csv`) разбить `raw_line` на отдельные поля (каждое поле — отдельная строка результата) с помощью `regexp_split_to_table`, правильно обрабатывая запятые внутри кавычек в простых случаях.
10. Во всех строках логов (`import_log.txt`) заменить любые вхождения слова `error` в любом регистре на `ERROR` с помощью `regexp_replace` (глобально и регистронезависимо).

</details>

---

<details>
<summary><strong style="font-size: 16px;">Вариант 2</strong></summary>

В систему интернет-магазина приходят выгрузки заказов из трёх источников: внешние маркетплейсы, CSV-файлы от маркетинга и лог-файлы обработчика. Строки импорта содержат контактные данные покупателей, артикулы товаров (SKU), метки/категории через запятую, поля с ценами (иногда с тысячными разделителями) и диагностические сообщения из этапа обработки. Перед загрузкой нужно проверить корректность данных, извлечь ключевые поля и нормализовать номера/цены.

Вам дана таблица `orders_import_lines` — необработанные строки импорта. Напишите SQL-запросы с регулярными выражениями и функциями PostgreSQL для анализа и предобработки.

---

## SQL — создание и наполнение таблицы (реалистичные записи)

```sql
DROP TABLE IF EXISTS orders_import_lines;
CREATE TABLE orders_import_lines (
  id serial PRIMARY KEY,
  source_file text NOT NULL,   -- имя файла/источника
  line_no int NOT NULL,        -- номер строки
  raw_line text NOT NULL,      -- необработанная строка
  imported_at timestamptz default now(),
  note text
);

INSERT INTO orders_import_lines (source_file, line_no, raw_line, note) VALUES
-- Контакты покупателей: email в угловых скобках и простые варианты, телефоны в разных форматах
('marketplace_A_2025_11.csv', 1, 'Order#1001; Customer: Olga Petrova <olga.petrova@example.com>; +7 (921) 555-12-34; Items: SKU:AB-123-XY x1', 'order row'),
('marketplace_A_2025_11.csv', 2, 'Order#1002; Customer: Ivan <ivan@@example..com>; 8-921-5551234; Items: SKU:zx9999 x2', 'order row'),
('newsletter_upload.csv', 10, 'john.doe@domain.com; +44 7700 900123; tags: promo, holiday', 'marketing upload'),

-- Цены с разделителями тысяч и валютой
('pricing_feed.csv', 3, 'product: ZX-11; price: "1,299.99" USD', 'price row'),
('pricing_feed.csv', 4, 'product: Y-200; price: "2 500,00" EUR', 'price row'),

-- Теги/категории в поле tags:
('catalog_tags.csv', 1, 'tags: electronics, mobile,  accessories', 'tags row'),
('catalog_tags.csv', 2, 'tags: home,kitchen', 'tags row'),

-- «Грязные» CSV-строки: запятые внутри полей, кавычки
('orders_dirty.csv', 5, '"Smith, John","12 Baker St, Apt 4","1,200.00","SKU: AB-123-XY"', 'dirty csv'),

-- Логи обработки: разного регистра, ошибки и предупреждения
('processor_log.txt', 100, 'INFO: Processing order 1001', 'log'),
('processor_log.txt', 101, 'warning: price parse failed for line 4', 'log'),
('processor_log.txt', 102, 'Error: invalid phone for order 1002', 'log'),
('processor_log.txt', 103, 'error: missing sku in items list', 'log'),

-- Ловушки / edge-cases для проверки наивных regex
('marketplace_A_2025_11.csv', 20, 'Customer: bad@-domain.com; +7 921 ABC-12-34; Items: SKU: 12-AB-!!', 'trap-invalid-email-phone-sku'),
('orders_dirty.csv', 6, '"O\'Connor, Liam","New York, NY","500"', 'dirty csv with apostrophe');
```

---

## Задания (формулировка для студента / проверки)

1. Найти все строки, содержащие корректный email (включая случаи с угловыми скобками), используя оператор `~`.
2. Найти строки, **не** содержащие корректный email, используя оператор `!~`.
3. Извлечь первый email из поля `raw_line` для каждой строки, где он есть, используя `regexp_match` (вернуть id, source_file, line_no, email).
4. Извлечь все SKU/артикулы (подходящие форматы, например `AB-123-XY`, `ZX-11`, `Y-200`, `zx9999`) из `raw_line` с помощью `regexp_matches` (учесть множественные совпадения).
5. Нормализовать телефонные номера: для строк, содержащих телефон, вернуть строку, в которой остаются только цифры (удалить пробелы, скобки, плюсы и дефисы) с помощью `regexp_replace`.
6. Преобразовать ценовые поля в числовой формат: убрать пробелы/запятые-разделители тысячи и привести к стандартному десятичному виду (например, `1,299.99` → `1299.99`), используя `regexp_replace` и/или приведение типов.
7. Для строк с `tags:` разбить список тегов на массив (убрать пустые элементы и лишние пробелы) с помощью `regexp_split_to_array`.
8. Для строк из `orders_dirty.csv` разбить `raw_line` на отдельные поля (каждое поле — отдельная строка результата) с `regexp_split_to_table`, корректно обрабатывая запятые внутри кавычек в простых случаях.
9. Найти в логах (`source_file = 'processor_log.txt'`) все строки, где встречается слово `error` (в любом регистре) — используйте `~*`.
10. Во всех строках логов заменить любые вхождения слова `error` в любом регистре на `ERROR` (глобально и регистронезависимо) с помощью `regexp_replace`.

</details>

---

<details>
<summary><strong style="font-size: 16px;">Вариант 3</strong></summary>

В систему мониторинга IoT-устройств поступают выгрузки от шлюзов и заводских скриптов: строки телеметрии, идентификаторы устройств (различные форматы), версии прошивок, метки/теги устройства, поля с размерами/параметрами (иногда с разделителями), а также логи ошибок и предупреждений. Нужно проверить корректность идентификаторов, извлечь email техподдержки из примечаний, нормализовать версии и числовые поля, а также проанализировать логи.

Вам дана таблица `iot_ingest_lines` — необработанные строки импорта. Напишите SQL-запросы с использованием регулярных выражений и функций PostgreSQL для анализа и предобработки.

---

## SQL — создание и наполнение таблицы (реалистичные записи)

```sql
DROP TABLE IF EXISTS iot_ingest_lines;
CREATE TABLE iot_ingest_lines (
  id serial PRIMARY KEY,
  source_file text NOT NULL,
  line_no int NOT NULL,
  raw_line text NOT NULL,
  received_at timestamptz default now(),
  note text
);

INSERT INTO iot_ingest_lines (source_file, line_no, raw_line, note) VALUES
-- Телеметрия: device_id в разных форматах, параметры, контакт техподдержки
('gateway_A_2025_11.log', 1, 'DEV_ID: DEV-AB12-3456; fw: v1.2.3; temp: 23.5C; support: ops@example.com', 'telemetry row'),
('gateway_A_2025_11.log', 2, 'device: abcd1234; fw: 1.02; humidity: "45,2"% ; support: help@iot-co.co', 'telemetry row'),
('gateway_B_2025_11.log', 3, 'ID: dev:XY_99-0001; fw: v01.2; size: "1,200" bytes; note: owner@example..com', 'telemetry with bad email'),

-- Версии прошивки и параметры с пробелами/десят. и тысячными разделителями
('factory_feed.csv', 10, 'serial: SN-0001; version: 2.0.1; storage: "1 024"', 'factory row'),
('factory_feed.csv', 11, 'serial: SN0002; version: v2.0; storage: "512"', 'factory row'),

-- Теги/метки устройства
('device_tags.csv', 1, 'tags: edge, sensor, temperature', 'tags row'),
('device_tags.csv', 2, 'tags: gateway, , backbone', 'tags with empty'),

-- «Грязные» CSV-строки: кавычки и запятые в полях (адреса установки, описания)
('installations_dirty.csv', 5, '"Site, North","Rack 12, Unit 4","x:100,y:200"', 'dirty csv'),
('installations_dirty.csv', 6, '"O\'Hara, Plant","Area A, Sector 7","notes: needs inspection"', 'dirty csv with apostrophe'),

-- Логи обработки: разные регистры ошибок и предупреждений
('ingest_log.txt', 200, 'INFO: ingest started for gateway_A_2025_11.log', 'log'),
('ingest_log.txt', 201, 'Warning: missing fw version for SN0002', 'log'),
('ingest_log.txt', 202, 'error: failed to parse telemetry line 3', 'log'),
('ingest_log.txt', 203, 'Error: device id malformed', 'log'),

-- Ловушки / edge-cases для проверки наивных regex
('gateway_A_2025_11.log', 20, 'DEV_ID: bad@-id; support: ops@@example.com; fw: v1..2', 'trap-bad-id-email-fw'),
('device_tags.csv', 3, 'tags: sensor,, ,temperature', 'trap-empty-tags');
```

---

## Задания (формулировка для студента / проверки)

1. Найти все строки, содержащие корректный email контакта/поддержки (учтите случаи с обычным email и с `support:`/`support` в тексте) — используйте оператор `~`.
2. Найти строки, **не** содержащие корректный email (учесть возможные «сломанные» варианты) — используйте оператор `!~`.
3. Извлечь первый email из `raw_line` для каждой строки, где он есть, используя `regexp_match` (вернуть id, source_file, line_no и email).
4. Найти строки с идентификаторами устройств (device id) в разных формах (примеры форматов: `DEV-AB12-3456`, `abcd1234`, `dev:XY_99-0001`, `SN-0001`) — используйте `~`/`~*` и составьте регулярное выражение для извлечения id.
5. Извлечь все совпадения версий прошивки (например `v1.2.3`, `1.02`, `v01.2`, `2.0.1`) из `raw_line` с `regexp_matches` (учесть множественные совпадения при необходимости).
6. Нормализовать числовые поля: убрать пробелы и запятые-разделители тысяч в полях типа `storage`, `size` и привести их к чистым числам (например, `"1 024"` → `1024`, `"1,200"` → `1200`) с помощью `regexp_replace` и/или приведения типов.
7. Для строк с `tags:` разбить список тегов на массив (убрать пустые элементы и лишние пробелы) с помощью `regexp_split_to_array`.
8. Для строк из `installations_dirty.csv` разбить `raw_line` на отдельные поля (каждое поле — отдельная строка результата) с `regexp_split_to_table`, корректно обрабатывая запятые внутри кавычек в простых случаях.
9. В логах (`ingest_log.txt`) найти все строки, где встречается слово `error` (в любом регистре) — используйте `~*`.
10. Во всех строках логов заменить любые вхождения слова `error` в любом регистре на `ERROR` (глобально и регистронезависимо) с помощью `regexp_replace`.


</details>

---

<details>
<summary><strong style="font-size: 16px;">Вариант 4</strong></summary>

Агрегатор получает выгрузки бронирований от партнёров: строки содержат контактные данные пассажиров, PNR/booking-коды, номера рейсов/ваучеров, цены с разными форматами, даты в разных локалях, теги/метки (например, «vip», «flex»), а также лог-записи обработчика импорта. Перед загрузкой в основную систему нужно валидировать и очищать данные: извлечь email/PNR, нормализовать телефоны и цены, корректно распарсить «грязные» CSV-строки и проанализировать логи.

Вам дана таблица `bookings_import_lines` — необработанные строки импорта. Напишите SQL-запросы с регулярными выражениями и функциями PostgreSQL для проверки и предобработки.

---

## SQL — создание и наполнение таблицы (реалистичные записи)

```sql
DROP TABLE IF EXISTS bookings_import_lines;
CREATE TABLE bookings_import_lines (
  id serial PRIMARY KEY,
  source_file text NOT NULL,
  line_no int NOT NULL,
  raw_line text NOT NULL,
  imported_at timestamptz default now(),
  note text
);

INSERT INTO bookings_import_lines (source_file, line_no, raw_line, note) VALUES
-- Контакты пассажиров: email в угловых скобках и простые варианты, телефоны
('partnerA_2025_11.csv', 1, 'PNR: ABC123; Passenger: Ivan Petrov <ivan.petrov@example.com>; +7 (916) 111-22-33; Fare: "1,299.00" USD', 'booking row'),
('partnerA_2025_11.csv', 2, 'PNR: XYZ-999; Passenger: Maria; maria.s@mail.co; 8-916-1112233; Fare: "1 250,00" EUR', 'booking row'),
('partnerA_2025_11.csv', 3, 'PNR: BAD@@PNR; Passenger: Oops <bad@-domain.com>; +7 916 ABC-22-33; Fare: "999"', 'broken pnr and email'),

-- Номера рейсов и ваучеров, разные форматы PNR/SKU
('carrier_feed.csv', 10, 'Voucher: VCHR-2025-0001; Flight: SU1234; seat: 12A', 'voucher row'),
('carrier_feed.csv', 11, 'Booking: pnr: qwe987; note: legacy', 'booking row'),

-- Даты в разных форматах (DD/MM/YYYY, YYYY-MM-DD, Month DD, YYYY)
('dates_feed.csv', 1, 'checkin: 05/12/2025; checkout: 12/12/2025', 'dates'),
('dates_feed.csv', 2, 'checkin: 2025-12-05; checkout: 2025-12-12', 'iso dates'),
('dates_feed.csv', 3, 'checkin: Dec 5, 2025; checkout: Dec 12, 2025', 'text month'),

-- Теги/метки
('flags.csv', 1, 'tags: vip,flex, refundable ', 'tags row'),
('flags.csv', 2, 'tags: economy, , promo', 'tags with possible empty'),

-- «Грязные» CSV-строки: имена и адреса с запятыми и кавычками
('passenger_dirty.csv', 5, '"Ivanov, Ivan","123 Red St, Apt 4","Passport: 123-45-678"', 'dirty csv'),
('passenger_dirty.csv', 6, '"Smith, Anna","Los Angeles, CA","Notes: needs wheelchair"', 'dirty csv'),

-- Логи обработчика (разного регистра)
('import_log.txt', 300, 'INFO: started bookings import', 'log'),
('import_log.txt', 301, 'warning: missing fare for line 3', 'log'),
('import_log.txt', 302, 'error: failed to parse PNR for line 3', 'log'),
('import_log.txt', 303, 'Error: invalid date format in dates_feed.csv', 'log'),

-- Ловушки / edge-cases
('partnerA_2025_11.csv', 20, 'PNR: 123 456; Passenger: bad@@example..com; Fare: "1,2,99"', 'trap-bad-pnr-email-price'),
('flags.csv', 3, 'tags: vip,, ,flex', 'trap-empty-tags');
```

---

## Задания (формулировка для студента / проверки)

1. Найти все строки, содержащие корректный email (включая варианты в угловых скобках) — используйте оператор `~`.
2. Найти строки, **не** содержащие корректный email — используйте оператор `!~`.
3. Найти строки с корректными PNR/booking-кодами (например `ABC123`, `XYZ-999`, `qwe987`) — используйте `~` и спроектируйте подходящее регулярное выражение.
4. Извлечь первый email из `raw_line` для каждой строки, где он есть, с помощью `regexp_match` (вернуть id, source_file, line_no, email).
5. Извлечь все номера рейсов/ваучеров (например `SU1234`, `VCHR-2025-0001`) с помощью `regexp_matches` (учесть множественные совпадения).
6. Нормализовать телефонные номера: для строк с телефонами вернуть строку с только цифрами (удалить пробелы, скобки, плюсы и дефисы) с помощью `regexp_replace`.
7. Преобразовать ценовые поля в числовой формат: убрать разделители тысяч (запятые или пробелы) и привести к стандартному десятичному виду (например, `"1,299.00"` → `1299.00`, `"1 250,00"` → `1250.00`) — используйте `regexp_replace` и/или приведение типов.
8. Для строк с `tags:` разбить список тегов на массив тегов (убрать пустые элементы и лишние пробелы) с помощью `regexp_split_to_array`.
9. Для строк из `passenger_dirty.csv` разбить `raw_line` на отдельные поля (каждое поле — отдельная строка результата) с помощью `regexp_split_to_table`, корректно учитывая запятые внутри кавычек в простых случаях.
10. В логах (`import_log.txt`) найти все строки, где встречается слово `error` (в любом регистре) — используйте `~*`, и затем заменить все такие вхождения на `ERROR` глобально и регистронезависимо с `regexp_replace`.

</details>

---

<details>
<summary><strong style="font-size: 16px;">Вариант 5</strong></summary>

Система страховой компании получает выгрузки претензий и медицинских форм от клиник и партнёров: строки содержат контактные данные пациентов, номера полисов/claim-id, коды процедур (CPT/ICD-формат), суммы выплат с разными форматами, даты и примечания (иногда с email техподдержки), а также логи обработки. Перед загрузкой в основную систему нужно валидировать поля, извлечь email/полисы, нормализовать суммы и телефоны, корректно распарсить «грязные» CSV-строки и проанализировать логи.

Вам дана таблица `claims_import_lines` — необработанные строки импорта. Напишите SQL-запросы с регулярными выражениями и функциями PostgreSQL для проверки и предобработки.

---

## SQL — создание и наполнение таблицы (реалистичные записи)

```sql
DROP TABLE IF EXISTS claims_import_lines;
CREATE TABLE claims_import_lines (
  id serial PRIMARY KEY,
  source_file text NOT NULL,
  line_no int NOT NULL,
  raw_line text NOT NULL,
  received_at timestamptz default now(),
  note text
);

INSERT INTO claims_import_lines (source_file, line_no, raw_line, note) VALUES
-- Контакты пациентов: email в угловых скобках и простые варианты, телефоны
('clinic_A_2025_11.csv', 1, 'Claim#C1001; Patient: Ivan Petrov <ivan.petrov@example.com>; +7 (900) 123-45-67; Policy: POL-12345', 'claim row'),
('clinic_A_2025_11.csv', 2, 'Claim#C1002; Patient: Olga S; olga.s@mail.co; 8-900-1234567; Policy: POL67890', 'claim row'),
('clinic_A_2025_11.csv', 3, 'Claim#C1003; Patient: Oops <bad@-domain.com>; 09001234567; Policy: BAD@@POL', 'broken email/policy'),

-- Процедурные коды и суммы (с разделителями тысяч и валютой)
('billing_feed.csv', 10, 'proc: CPT-99213; amount: "1,200.00" USD; provider: Clinic A', 'billing row'),
('billing_feed.csv', 11, 'code: ICD10-A41.9; charge: "2 500,00" EUR; note: urgent', 'billing row'),

-- Теги/метки диагноза / категории
('diagnosis_tags.csv', 1, 'tags: urgent, inpatient, cardio', 'tags row'),
('diagnosis_tags.csv', 2, 'tags: outpatient, , followup', 'tags with empty'),

-- «Грязные» CSV-строки: фамилии с запятыми, адреса, суммы в кавычках
('patients_dirty.csv', 5, '"Ivanov, Ivan","123 Med St, Bldg 2","claim: C2001","1,500.00"', 'dirty csv'),
('patients_dirty.csv', 6, '"Brown, Sarah","Ward 7, Room 12","notes: needs translator","2 000,00"', 'dirty csv'),

-- Логи обработки: разного регистра, ошибки и предупреждения
('ingest_claims_log.txt', 400, 'INFO: started claims ingest', 'log'),
('ingest_claims_log.txt', 401, 'warning: missing policy for claim C1003', 'log'),
('ingest_claims_log.txt', 402, 'error: failed to parse patients_dirty.csv line 6', 'log'),
('ingest_claims_log.txt', 403, 'Error: amount format invalid for claim C1002', 'log'),

-- Ловушки / edge-cases для проверки наивных regex
('clinic_A_2025_11.csv', 20, 'Patient: bad@@example..com; phone: +7 900 ABC-45-67; Policy: POL-12-!!', 'trap-bad-email-phone-policy'),
('patients_dirty.csv', 7, '"O\'Neil, Patrick","100 Main St, Suite 5","claim: C2002",""', 'dirty csv with apostrophe and empty amount');
```

---

## Задания (формулировка для студента / проверки)

1. Найти все строки, содержащие корректный email контакта/пациента (учтите случаи с обычным email и с email в угловых скобках) — используйте оператор `~`.
2. Найти строки, **не** содержащие корректный email (учесть сломанные варианты) — используйте оператор `!~`.
3. Извлечь первый найденный email из `raw_line` для каждой строки, где он есть, с помощью `regexp_match` (вернуть id, source_file, line_no и email).
4. Найти и извлечь номера полисов/claim-id (например `POL-12345`, `POL67890`, `C1001`, `C2001`) — используйте `~`/`~*` и составьте подходящую регулярку для извлечения идентификаторов.
5. Извлечь все процедурные коды и ICD/CPT-форматы (например `CPT-99213`, `ICD10-A41.9`) из `raw_line` с помощью `regexp_matches` (учесть множественные совпадения).
6. Нормализовать суммы/charges: убрать разделители тысяч (запятые или пробелы) и привести к числовому/десятичному виду (например `"1,200.00"` → `1200.00`, `"2 500,00"` → `2500.00`) с применением `regexp_replace` и/или приведения типов.
7. Нормализовать телефонные номера: для строк с телефонами вернуть строку, содержащую только цифры (удалить пробелы, скобки, плюсы и дефисы) с помощью `regexp_replace`.
8. Для строк с `tags:` разбить список тегов на массив тегов (убрать пустые элементы и лишние пробелы) с помощью `regexp_split_to_array`.
9. Для строк из `patients_dirty.csv` разбить `raw_line` на отдельные поля (каждое поле — отдельная строка результата) с помощью `regexp_split_to_table`, корректно обрабатывая запятые внутри кавычек в простых случаях.
10. В логах (`ingest_claims_log.txt`) найти все строки, где встречается слово `error` в любом регистре — используйте `~*`, и затем заменить все такие вхождения на `ERROR` глобально и регистронезависимо с помощью `regexp_replace`.

</details>

---